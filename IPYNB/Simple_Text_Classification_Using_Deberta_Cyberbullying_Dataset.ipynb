{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"11QTZhH6bFJtK65OVTY8P9Y85on-ZEMlL","timestamp":1677270091757},{"file_id":"17EUnGuMD8zVFOn3cvMdFjYo7C_cdWcB-","timestamp":1677106793467}],"machine_shape":"hm","mount_file_id":"1pCQYcjiXjSQrZUpmIErpnWO7xv2tNukl","authorship_tag":"ABX9TyM2h53vAhluHzeo23OUvUtQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium","widgets":{"application/vnd.jupyter.widget-state+json":{"ac94e3304a1f4d2a88e383b8a0751e2c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a8b4ca8d7abe48b1b7a3dbf9f926d633","IPY_MODEL_41956e7132e645719397780ace9c819c","IPY_MODEL_05af5643c1264b1d9290970b43466013"],"layout":"IPY_MODEL_8a88d6ef49c44f7da502978af298e5b7"}},"a8b4ca8d7abe48b1b7a3dbf9f926d633":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_71332cfdfb614060a8d539eb1ae0ae25","placeholder":"​","style":"IPY_MODEL_c018146b12f44eea8ad0118fd96e10a2","value":"Downloading (…)okenizer_config.json: 100%"}},"41956e7132e645719397780ace9c819c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7eb71592bf244ab9bb203242b1c477c9","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f74f10b93dfa4d7298b93b5b374e3838","value":52}},"05af5643c1264b1d9290970b43466013":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c25a5914741249c5a27e67c809fef863","placeholder":"​","style":"IPY_MODEL_e0847ee7a7eb40b3b5349cb8054159a3","value":" 52.0/52.0 [00:00&lt;00:00, 2.72kB/s]"}},"8a88d6ef49c44f7da502978af298e5b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71332cfdfb614060a8d539eb1ae0ae25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c018146b12f44eea8ad0118fd96e10a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7eb71592bf244ab9bb203242b1c477c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f74f10b93dfa4d7298b93b5b374e3838":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c25a5914741249c5a27e67c809fef863":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0847ee7a7eb40b3b5349cb8054159a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da6b00deaecd45e79343a009f789a302":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6b4ee377f3d5481bab4594646ac48df8","IPY_MODEL_b7e0da5a70cf43489e17d06612ceac5a","IPY_MODEL_23718644aa9b4adb91f0f8f2a459d86b"],"layout":"IPY_MODEL_ca5addbe993d4529ba255e35f8e69831"}},"6b4ee377f3d5481bab4594646ac48df8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_86cb5ae3b15d4cf782117082e3fe72d2","placeholder":"​","style":"IPY_MODEL_d93880285e5b4c4db26be3436dff6f24","value":"Downloading (…)lve/main/config.json: 100%"}},"b7e0da5a70cf43489e17d06612ceac5a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb23c94351a140e1bb1b76c4af857c79","max":578,"min":0,"orientation":"horizontal","style":"IPY_MODEL_feb4bf75b1454378bbb73a191ce6558e","value":578}},"23718644aa9b4adb91f0f8f2a459d86b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3ca2dbbb35e40c9accb08ce60ff64eb","placeholder":"​","style":"IPY_MODEL_0d6e6ba0060745ff989190701d81aa37","value":" 578/578 [00:00&lt;00:00, 32.0kB/s]"}},"ca5addbe993d4529ba255e35f8e69831":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86cb5ae3b15d4cf782117082e3fe72d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d93880285e5b4c4db26be3436dff6f24":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb23c94351a140e1bb1b76c4af857c79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"feb4bf75b1454378bbb73a191ce6558e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e3ca2dbbb35e40c9accb08ce60ff64eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d6e6ba0060745ff989190701d81aa37":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"661316f5c49a425fb50faf8b4cd4a478":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e83e8f02663499499b98bc444fa9a76","IPY_MODEL_909ba96910e740e18d18db881e855af5","IPY_MODEL_716e487420df4be1a7e0a64bb36b1e11"],"layout":"IPY_MODEL_76c22f42a9f949378e6f31a9820b0ef7"}},"8e83e8f02663499499b98bc444fa9a76":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b9998fc9c654130931fc974efef3b4d","placeholder":"​","style":"IPY_MODEL_4a212066966d499492e817c5630dba7f","value":"Downloading (…)&quot;spm.model&quot;;: 100%"}},"909ba96910e740e18d18db881e855af5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8450a9e6ffa4dac87aeee8327cabdef","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0133e448f4a84c179a15b36c09be1a3f","value":2464616}},"716e487420df4be1a7e0a64bb36b1e11":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e5a791c13df40d8a4421811c23e84b5","placeholder":"​","style":"IPY_MODEL_1d8ba838612e42de946e6e4406c51711","value":" 2.46M/2.46M [00:00&lt;00:00, 76.2MB/s]"}},"76c22f42a9f949378e6f31a9820b0ef7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b9998fc9c654130931fc974efef3b4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a212066966d499492e817c5630dba7f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8450a9e6ffa4dac87aeee8327cabdef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0133e448f4a84c179a15b36c09be1a3f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4e5a791c13df40d8a4421811c23e84b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d8ba838612e42de946e6e4406c51711":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"afb198b70c4243f49f064c1341ec4161":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cd87c305c82e49d18197a977332eb8a3","IPY_MODEL_30148a1a5f464c1ca36addc97137fea3","IPY_MODEL_0b85907e9d374fdf882c57d7ea3554d4"],"layout":"IPY_MODEL_6ef2ce2e674c45e8aa7725a011f4dc07"}},"cd87c305c82e49d18197a977332eb8a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_760c006a87074cd6a4afd7adfe24c977","placeholder":"​","style":"IPY_MODEL_8ad3a935db9641218b3c3de328ed5dd6","value":"Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"}},"30148a1a5f464c1ca36addc97137fea3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0269264ea7c24a50b4062d92d02a1ffb","max":286059269,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aea038d266a5484d88221f1e196ac4cb","value":286059269}},"0b85907e9d374fdf882c57d7ea3554d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6893e6ab64bc4998b3600584132b98cb","placeholder":"​","style":"IPY_MODEL_4635ebd65cbb4207b6388549047f5595","value":" 286M/286M [00:00&lt;00:00, 340MB/s]"}},"6ef2ce2e674c45e8aa7725a011f4dc07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"760c006a87074cd6a4afd7adfe24c977":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ad3a935db9641218b3c3de328ed5dd6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0269264ea7c24a50b4062d92d02a1ffb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aea038d266a5484d88221f1e196ac4cb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6893e6ab64bc4998b3600584132b98cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4635ebd65cbb4207b6388549047f5595":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# This is the Fine-Tuning for Text Classification simple example\n","# Part 3: Converting binary DeBerta to multi-class classification\n","#         using the data sets from Cyberbullying\n","- https://towardsdatascience.com/fine-tuning-bert-for-text-classification-54e7df642894\n","\n","# NOTE: I need to review the Huggingface set of documentations and videos\n","#       example is: https://huggingface.co/docs/transformers/training "],"metadata":{"id":"eLD0nCN1Ufok"}},{"cell_type":"code","source":["# put drive connection code if needed\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd drive/MyDrive/Github/\n","!pwd"],"metadata":{"id":"rTMPrUQbW_Rt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677356133618,"user_tz":300,"elapsed":7022,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"927d8756-07df-41f2-beb9-ff4eae06e034"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Github\n","/content/drive/MyDrive/Github\n"]}]},{"cell_type":"code","source":["!git config --global user.email \"bgoldfe2@gmu.edu\"\n","!git config --global user.name \"Bruce Goldfeder\"\n","\n","!cp -R ssh/ ~/.ssh\n","!ls -alh ~/.ssh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rr0z2WrsQRyY","executionInfo":{"status":"ok","timestamp":1677356139231,"user_tz":300,"elapsed":3408,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"393fa0b7-8502-481c-96a0-b5a84123b1f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total 20K\n","drwx------ 2 root root 4.0K Feb 25 20:15 .\n","drwx------ 1 root root 4.0K Feb 25 20:15 ..\n","-rw------- 1 root root 3.2K Feb 25 20:15 id_rsa\n","-rw------- 1 root root  742 Feb 25 20:15 id_rsa.pub\n"]}]},{"cell_type":"code","source":["# Code to install the nightly version if needed for debugging\n","\n","#!nvcc --version\n","#!pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu117"],"metadata":{"id":"sV4rdGMLpL3n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers\n","# Helps when using fast tokenizers\n","!pip install sentencepiece"],"metadata":{"id":"FOjkyiXPUF3b"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5lz0BNh8T8Rm"},"outputs":[],"source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from transformers import AutoModelForSequenceClassification,AutoTokenizer\n","from sklearn.model_selection import train_test_split\n","\n","import pandas as pd\n","import numpy as np\n","\n","from tabulate import tabulate\n","from tqdm import trange\n","import random\n","import math\n","\n","import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""]},{"cell_type":"code","source":["!pwd\n","%cd dissertation-ground-up-version/Dataset/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HXaLxOjOT9fn","executionInfo":{"status":"ok","timestamp":1677356162702,"user_tz":300,"elapsed":6,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"c0485be8-80b1-40a9-b0fd-cfa070550d2b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Github\n","/content/drive/MyDrive/Github/dissertation-ground-up-version/Dataset\n"]}]},{"cell_type":"code","source":["%cd SixClass/\n","!head -10 train.csv"],"metadata":{"id":"hpCzALb8UeN6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(\"train.csv\")\n","\n","# First 5 rows\n","display(df.head())\n","df2 = df[['label', 'target']]\n","df3 = (df2.drop_duplicates()).sort_values('target')\n","print(tabulate(df3, headers='keys', tablefmt='github', showindex=False))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":345},"id":"Et1v1DLzC3OT","executionInfo":{"status":"ok","timestamp":1677356166702,"user_tz":300,"elapsed":1347,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"4bd1feb6-4826-4522-f833-8e017d8f6da4"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["   Unnamed: 0                                               text     label  \\\n","0       38746  #trumprussia sean spicer is a blithering idiot...    Others   \n","1       47265  If you call yourself a Christian yet you suppo...  Religion   \n","2       36632                    Small red lights in dark rooms.    Others   \n","3       29064  If u find yourself pouting that no male report...     Notcb   \n","4       33884  Messi carried these retards to three consecuti...    Others   \n","\n","   target  \n","0       4  \n","1       5  \n","2       4  \n","3       3  \n","4       4  "],"text/html":["\n","  <div id=\"df-96084b22-3451-47a4-bf74-a16aa65b369f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>38746</td>\n","      <td>#trumprussia sean spicer is a blithering idiot...</td>\n","      <td>Others</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>47265</td>\n","      <td>If you call yourself a Christian yet you suppo...</td>\n","      <td>Religion</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36632</td>\n","      <td>Small red lights in dark rooms.</td>\n","      <td>Others</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>29064</td>\n","      <td>If u find yourself pouting that no male report...</td>\n","      <td>Notcb</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>33884</td>\n","      <td>Messi carried these retards to three consecuti...</td>\n","      <td>Others</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96084b22-3451-47a4-bf74-a16aa65b369f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-96084b22-3451-47a4-bf74-a16aa65b369f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-96084b22-3451-47a4-bf74-a16aa65b369f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["| label     |   target |\n","|-----------|----------|\n","| Age       |        0 |\n","| Ethnicity |        1 |\n","| Gender    |        2 |\n","| Notcb     |        3 |\n","| Others    |        4 |\n","| Religion  |        5 |\n"]}]},{"cell_type":"code","source":["df.drop(df.columns[[0, 2]], axis=1, inplace=True)\n","df.rename(columns = {'target':'label'}, inplace = True)\n","display(df.head())"],"metadata":{"id":"Iai7SUzGVQ4H","executionInfo":{"status":"ok","timestamp":1677356166703,"user_tz":300,"elapsed":10,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"74fd42a5-061b-4710-cf1e-a6c6d365ca63"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["                                                text  label\n","0  #trumprussia sean spicer is a blithering idiot...      4\n","1  If you call yourself a Christian yet you suppo...      5\n","2                    Small red lights in dark rooms.      4\n","3  If u find yourself pouting that no male report...      3\n","4  Messi carried these retards to three consecuti...      4"],"text/html":["\n","  <div id=\"df-f647555c-6ebc-4dcc-b785-4aaaedeba1f7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>#trumprussia sean spicer is a blithering idiot...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>If you call yourself a Christian yet you suppo...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Small red lights in dark rooms.</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>If u find yourself pouting that no male report...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Messi carried these retards to three consecuti...</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f647555c-6ebc-4dcc-b785-4aaaedeba1f7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f647555c-6ebc-4dcc-b785-4aaaedeba1f7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f647555c-6ebc-4dcc-b785-4aaaedeba1f7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["df.groupby(['label']).size().plot.bar()\n","\n","# Need to implement custom Dataset as in https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"id":"AbN6Nlc0PN-y","executionInfo":{"status":"ok","timestamp":1677356166704,"user_tz":300,"elapsed":10,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"fbc6e070-d337-402a-bff3-d784056134f8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<AxesSubplot:xlabel='label'>"]},"metadata":{},"execution_count":9},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["model_nm = 'microsoft/deberta-v3-small'\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_nm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202,"referenced_widgets":["ac94e3304a1f4d2a88e383b8a0751e2c","a8b4ca8d7abe48b1b7a3dbf9f926d633","41956e7132e645719397780ace9c819c","05af5643c1264b1d9290970b43466013","8a88d6ef49c44f7da502978af298e5b7","71332cfdfb614060a8d539eb1ae0ae25","c018146b12f44eea8ad0118fd96e10a2","7eb71592bf244ab9bb203242b1c477c9","f74f10b93dfa4d7298b93b5b374e3838","c25a5914741249c5a27e67c809fef863","e0847ee7a7eb40b3b5349cb8054159a3","da6b00deaecd45e79343a009f789a302","6b4ee377f3d5481bab4594646ac48df8","b7e0da5a70cf43489e17d06612ceac5a","23718644aa9b4adb91f0f8f2a459d86b","ca5addbe993d4529ba255e35f8e69831","86cb5ae3b15d4cf782117082e3fe72d2","d93880285e5b4c4db26be3436dff6f24","cb23c94351a140e1bb1b76c4af857c79","feb4bf75b1454378bbb73a191ce6558e","e3ca2dbbb35e40c9accb08ce60ff64eb","0d6e6ba0060745ff989190701d81aa37","661316f5c49a425fb50faf8b4cd4a478","8e83e8f02663499499b98bc444fa9a76","909ba96910e740e18d18db881e855af5","716e487420df4be1a7e0a64bb36b1e11","76c22f42a9f949378e6f31a9820b0ef7","4b9998fc9c654130931fc974efef3b4d","4a212066966d499492e817c5630dba7f","b8450a9e6ffa4dac87aeee8327cabdef","0133e448f4a84c179a15b36c09be1a3f","4e5a791c13df40d8a4421811c23e84b5","1d8ba838612e42de946e6e4406c51711"]},"id":"TLGat00iVUzq","executionInfo":{"status":"ok","timestamp":1677356174776,"user_tz":300,"elapsed":8080,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"9a5af4e3-ac1f-4e15-ca33-5f1fc823395a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac94e3304a1f4d2a88e383b8a0751e2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da6b00deaecd45e79343a009f789a302"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)\"spm.model\";:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"661316f5c49a425fb50faf8b4cd4a478"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","/usr/local/lib/python3.8/dist-packages/transformers/convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["print(type(tokenizer))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VH7DtwaqiiV9","executionInfo":{"status":"ok","timestamp":1677356174777,"user_tz":300,"elapsed":15,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"7f3565d0-975f-47b0-9af8-6dedf2eb33d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'transformers.models.deberta_v2.tokenization_deberta_v2_fast.DebertaV2TokenizerFast'>\n"]}]},{"cell_type":"code","source":["# Create lists of texts and labels\n","text = df.text.values\n","labels = df.label.values\n","\n","def print_rand_sentence():\n","  '''Displays the tokens and respective IDs of a random text sample'''\n","  index = random.randint(0, len(text)-1)\n","  table = np.array([tokenizer.tokenize(text[index]), \n","                    tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text[index]))]).T\n","  print(tabulate(table,\n","                 headers = ['Tokens', 'Token IDs'],\n","                 tablefmt = 'fancy_grid'))\n","\n","print_rand_sentence()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zzqWr_EpVa88","executionInfo":{"status":"ok","timestamp":1677356174777,"user_tz":300,"elapsed":12,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"94db9af3-368f-41c2-c352-f0dc28ff8b11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["╒════════════╤═════════════╕\n","│ Tokens     │   Token IDs │\n","╞════════════╪═════════════╡\n","│ ▁there     │         343 │\n","├────────────┼─────────────┤\n","│ s          │         268 │\n","├────────────┼─────────────┤\n","│ ▁this      │         291 │\n","├────────────┼─────────────┤\n","│ ▁person    │         604 │\n","├────────────┼─────────────┤\n","│ ▁that      │         272 │\n","├────────────┼─────────────┤\n","│ ▁used      │         427 │\n","├────────────┼─────────────┤\n","│ ▁to        │         264 │\n","├────────────┼─────────────┤\n","│ ▁bully     │       21319 │\n","├────────────┼─────────────┤\n","│ ▁me        │         351 │\n","├────────────┼─────────────┤\n","│ ▁in        │         267 │\n","├────────────┼─────────────┤\n","│ ▁school    │         563 │\n","├────────────┼─────────────┤\n","│ ▁and       │         263 │\n","├────────────┼─────────────┤\n","│ ▁now       │         394 │\n","├────────────┼─────────────┤\n","│ ▁they      │         306 │\n","├────────────┼─────────────┤\n","│ ve         │         415 │\n","├────────────┼─────────────┤\n","│ ▁had       │         330 │\n","├────────────┼─────────────┤\n","│ ▁a         │         266 │\n","├────────────┼─────────────┤\n","│ ▁job       │         688 │\n","├────────────┼─────────────┤\n","│ ▁at        │         288 │\n","├────────────┼─────────────┤\n","│ ▁almost    │         823 │\n","├────────────┼─────────────┤\n","│ ▁every     │         469 │\n","├────────────┼─────────────┤\n","│ ▁store     │        1106 │\n","├────────────┼─────────────┤\n","│ ▁in        │         267 │\n","├────────────┼─────────────┤\n","│ ▁my        │         312 │\n","├────────────┼─────────────┤\n","│ ▁town      │        1240 │\n","├────────────┼─────────────┤\n","│ ▁and       │         263 │\n","├────────────┼─────────────┤\n","│ ▁every     │         469 │\n","├────────────┼─────────────┤\n","│ ▁time      │         326 │\n","├────────────┼─────────────┤\n","│ ▁i         │         584 │\n","├────────────┼─────────────┤\n","│ ▁walk      │        1358 │\n","├────────────┼─────────────┤\n","│ ▁in        │         267 │\n","├────────────┼─────────────┤\n","│ ▁and       │         263 │\n","├────────────┼─────────────┤\n","│ ▁see       │         398 │\n","├────────────┼─────────────┤\n","│ ▁them      │         349 │\n","├────────────┼─────────────┤\n","│ ▁behind    │         931 │\n","├────────────┼─────────────┤\n","│ ▁a         │         266 │\n","├────────────┼─────────────┤\n","│ ▁new       │         353 │\n","├────────────┼─────────────┤\n","│ ▁register  │        2983 │\n","├────────────┼─────────────┤\n","│ ,          │         261 │\n","├────────────┼─────────────┤\n","│ ▁my        │         312 │\n","├────────────┼─────────────┤\n","│ ▁fight     │        1801 │\n","├────────────┼─────────────┤\n","│ ▁or        │         289 │\n","├────────────┼─────────────┤\n","│ ▁flight    │        2541 │\n","├────────────┼─────────────┤\n","│ ▁activates │       28922 │\n","╘════════════╧═════════════╛\n"]}]},{"cell_type":"code","source":["labels = {'Age':0,\n","          'Ethnicity':1,\n","          'Gender':2,\n","          'Notcb':3,\n","          'Others':4,\n","          'Religion' :5\n","          }\n","\n","class Dataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, df):\n","\n","        self.labels = [labels[label] for label in df['category']]\n","        self.texts = [tokenizer(text, \n","                               padding='max_length', max_length = 128, truncation=True,\n","                                return_tensors=\"pt\") for text in df['text']]\n","\n","    def classes(self):\n","        return self.labels\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def get_batch_labels(self, idx):\n","        # Fetch a batch of labels\n","        return np.array(self.labels[idx])\n","\n","    def get_batch_texts(self, idx):\n","        # Fetch a batch of inputs\n","        return self.texts[idx]\n","\n","    def __getitem__(self, idx):\n","\n","        batch_texts = self.get_batch_texts(idx)\n","        batch_y = self.get_batch_labels(idx)\n","\n","        return batch_texts, batch_y"],"metadata":{"id":"_BxA2KCrESkK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["token_id = []\n","attention_masks = []\n","\n","def preprocessing(input_text, tokenizer):\n","  '''\n","  Returns <class transformers.tokenization_utils_base.BatchEncoding> with the following fields:\n","    - input_ids: list of token ids\n","    - token_type_ids: list of token type ids\n","    - attention_mask: list of indices (0,1) specifying which tokens should considered by the model (return_attention_mask = True).\n","  '''\n","  return tokenizer.encode_plus(\n","                        input_text,\n","                        add_special_tokens = True,\n","                        max_length = 128,\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,\n","                        return_tensors = 'pt',\n","                        truncation=True\n","                   )\n","\n","\n","for sample in text:\n","  encoding_dict = preprocessing(sample, tokenizer)\n","  token_id.append(encoding_dict['input_ids']) \n","  attention_masks.append(encoding_dict['attention_mask'])\n","\n","\n","token_id = torch.cat(token_id, dim = 0)\n","attention_masks = torch.cat(attention_masks, dim = 0)\n","labels = torch.tensor(labels)"],"metadata":{"id":"1hs9CF6TVkeX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677356198853,"user_tz":300,"elapsed":9324,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"a2160924-8d49-4590-8512-5e4bf471a65e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["token_id[6]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y-CaLReyWYGz","executionInfo":{"status":"ok","timestamp":1677356203155,"user_tz":300,"elapsed":318,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"ef27258f-1438-4a4e-fe02-dc4a6d485968"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([    1,  1715,   280,   268,   831,   664,   265,   262,   485,   920,\n","         2921,   260,   336,   540,   277,  5292,   277, 88953,   260,  5372,\n","         2071,  2340,   281,   307, 45008,  5415,   355,   309,   277,   262,\n","          423,   260,  2135,  1519,   260,   260,   260,   724,  1863,  3103,\n","          267,   262,   697,   696,  2591,   266,  2132,  1220,   263,  2560,\n","         1471,  3790,  3930,   260,  6359,   363,   300,   300,   300,   300,\n","          300,   300,   300,   300,     2,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0])"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["def print_rand_sentence_encoding():\n","  '''Displays tokens, token IDs and attention mask of a random text sample'''\n","  index = random.randint(0, len(text) - 1)\n","  tokens = tokenizer.tokenize(tokenizer.decode(token_id[index]))\n","  token_ids = [i.numpy() for i in token_id[index]]\n","  attention = [i.numpy() for i in attention_masks[index]]\n","\n","  table = np.array([tokens, token_ids, attention]).T\n","  print(tabulate(table, \n","                 headers = ['Tokens', 'Token IDs', 'Attention Mask'],\n","                 tablefmt = 'fancy_grid'))\n","\n","print_rand_sentence_encoding()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8HXLgfPCWdfJ","executionInfo":{"status":"ok","timestamp":1677356207827,"user_tz":300,"elapsed":315,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"aef1d11f-d328-4583-f4cf-3d66f316d825"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["╒═════════════╤═════════════╤══════════════════╕\n","│ Tokens      │   Token IDs │   Attention Mask │\n","╞═════════════╪═════════════╪══════════════════╡\n","│ [CLS]       │           1 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁@          │        1944 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ S           │         430 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ iraj        │      106791 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ Z           │        3206 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ aroo        │       48281 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ k           │        1165 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁@          │        1944 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ Bil         │       88971 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ al          │        1544 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ IG          │       26135 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ hum         │       22533 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ man         │        1246 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁@          │        1944 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ O           │        1702 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ d           │         407 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ inia        │       50370 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ In          │        2514 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ vi          │        8007 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ctus        │       50023 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁@          │        1944 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ Israeli     │       41857 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ Reg         │       37850 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ime         │       27391 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁There      │         443 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁is         │         269 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁no         │         363 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁ongoing    │        3323 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁endless    │        6130 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁occupation │        8737 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁anywhere   │        2619 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ .           │         260 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [SEP]       │           2 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","╘═════════════╧═════════════╧══════════════════╛\n"]}]},{"cell_type":"code","source":["val_ratio = 0.2\n","# Recommended batch size: 16, 32. See: https://arxiv.org/pdf/1810.04805.pdf\n","batch_size = 32\n","\n","# Indices of the train and validation splits stratified by labels\n","train_idx, val_idx = train_test_split(\n","    np.arange(len(labels)),\n","    test_size = val_ratio,\n","    shuffle = True,\n","    stratify = labels)\n","\n","# Train and validation sets\n","train_set = TensorDataset(token_id[train_idx], \n","                          attention_masks[train_idx], \n","                          labels[train_idx])\n","\n","val_set = TensorDataset(token_id[val_idx], \n","                        attention_masks[val_idx], \n","                        labels[val_idx])\n","\n","# Prepare DataLoader\n","train_dataloader = DataLoader(\n","            train_set,\n","            sampler = RandomSampler(train_set),\n","            batch_size = batch_size\n","        )\n","\n","validation_dataloader = DataLoader(\n","            val_set,\n","            sampler = SequentialSampler(val_set),\n","            batch_size = batch_size\n","        )"],"metadata":{"id":"-UY6ZhNQWn45"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def b_tp(preds, labels):\n","  '''Returns True Positives (TP): count of correct predictions of actual class 1'''\n","  return sum([preds == labels and preds == 1 for preds, labels in zip(preds, labels)])\n","\n","def b_fp(preds, labels):\n","  '''Returns False Positives (FP): count of wrong predictions of actual class 1'''\n","  return sum([preds != labels and preds == 1 for preds, labels in zip(preds, labels)])\n","\n","def b_tn(preds, labels):\n","  '''Returns True Negatives (TN): count of correct predictions of actual class 0'''\n","  return sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)])\n","\n","def b_fn(preds, labels):\n","  '''Returns False Negatives (FN): count of wrong predictions of actual class 0'''\n","  return sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n","\n","def b_metrics(preds, labels):\n","  '''\n","  Returns the following metrics:\n","    - accuracy    = (TP + TN) / N\n","    - precision   = TP / (TP + FP)\n","    - recall      = TP / (TP + FN)\n","    - specificity = TN / (TN + FP)\n","  '''\n","  preds = np.argmax(preds, axis = 1).flatten()\n","  labels = labels.flatten()\n","  tp = b_tp(preds, labels)\n","  tn = b_tn(preds, labels)\n","  fp = b_fp(preds, labels)\n","  fn = b_fn(preds, labels)\n","  b_accuracy = (tp + tn) / len(labels)\n","  b_precision = tp / (tp + fp) if (tp + fp) > 0 else 'nan'\n","  b_recall = tp / (tp + fn) if (tp + fn) > 0 else 'nan'\n","  b_specificity = tn / (tn + fp) if (tn + fp) > 0 else 'nan'\n","  return b_accuracy, b_precision, b_recall, b_specificity"],"metadata":{"id":"t9RO9ncOYH_B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the SequenceClassification model\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    model_nm,\n","    num_labels = 6,\n","    output_attentions = False,\n","    output_hidden_states = False,\n",")\n","\n","# Recommended learning rates (Adam): 5e-5, 3e-5, 2e-5. See: https://arxiv.org/pdf/1810.04805.pdf\n","optimizer = torch.optim.AdamW(model.parameters(), \n","                              lr = 5e-5,\n","                              eps = 1e-08\n","                              )\n","\n","# Run on GPU\n","model.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["afb198b70c4243f49f064c1341ec4161","cd87c305c82e49d18197a977332eb8a3","30148a1a5f464c1ca36addc97137fea3","0b85907e9d374fdf882c57d7ea3554d4","6ef2ce2e674c45e8aa7725a011f4dc07","760c006a87074cd6a4afd7adfe24c977","8ad3a935db9641218b3c3de328ed5dd6","0269264ea7c24a50b4062d92d02a1ffb","aea038d266a5484d88221f1e196ac4cb","6893e6ab64bc4998b3600584132b98cb","4635ebd65cbb4207b6388549047f5595"]},"id":"H2QNBChoYScs","executionInfo":{"status":"ok","timestamp":1677356238814,"user_tz":300,"elapsed":11255,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"e273c7b3-5a2a-4cd8-dcb3-04bd4fd055d6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/286M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afb198b70c4243f49f064c1341ec4161"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-small were not used when initializing DebertaV2ForSequenceClassification: ['lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'pooler.dense.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["DebertaV2ForSequenceClassification(\n","  (deberta): DebertaV2Model(\n","    (embeddings): DebertaV2Embeddings(\n","      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n","      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","      (dropout): StableDropout()\n","    )\n","    (encoder): DebertaV2Encoder(\n","      (layer): ModuleList(\n","        (0): DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (1): DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (2): DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (3): DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (4): DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (5): DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","      )\n","      (rel_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","    )\n","  )\n","  (pooler): ContextPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): StableDropout()\n","  )\n","  (classifier): Linear(in_features=768, out_features=6, bias=True)\n","  (dropout): StableDropout()\n",")"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","\n","# Recommended number of epochs: 2, 3, 4. See: https://arxiv.org/pdf/1810.04805.pdf\n","epochs = 2\n","\n","for _ in trange(epochs, desc = 'Epoch'):\n","    \n","    # ========== Training ==========\n","    \n","    # Set model to training mode\n","    model.train()\n","    \n","    # Tracking variables\n","    tr_loss = 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","\n","    for step, batch in enumerate(train_dataloader):\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","        #print(b_labels)\n","        optimizer.zero_grad()\n","        # Forward pass\n","        train_output = model(b_input_ids, \n","                             token_type_ids = None, \n","                             attention_mask = b_input_mask, \n","                             labels = b_labels)\n","        # Backward pass\n","        train_output.loss.backward()\n","        optimizer.step()\n","        # Update tracking variables\n","        tr_loss += train_output.loss.item()\n","        nb_tr_examples += b_input_ids.size(0)\n","        nb_tr_steps += 1\n","\n","    # ========== Validation ==========\n","\n","    # Set model to evaluation mode\n","    model.eval()\n","\n","    # Tracking variables \n","    val_accuracy = []\n","    val_precision = []\n","    val_recall = []\n","    val_specificity = []\n","\n","    for batch in validation_dataloader:\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","        with torch.no_grad():\n","          # Forward pass\n","          eval_output = model(b_input_ids, \n","                              token_type_ids = None, \n","                              attention_mask = b_input_mask)\n","        logits = eval_output.logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        # Calculate validation metrics\n","        b_accuracy, b_precision, b_recall, b_specificity = b_metrics(logits, label_ids)\n","        val_accuracy.append(b_accuracy)\n","        # Update precision only when (tp + fp) !=0; ignore nan\n","        if b_precision != 'nan': val_precision.append(b_precision)\n","        # Update recall only when (tp + fn) !=0; ignore nan\n","        if b_recall != 'nan': val_recall.append(b_recall)\n","        # Update specificity only when (tn + fp) !=0; ignore nan\n","        if b_specificity != 'nan': val_specificity.append(b_specificity)\n","\n","    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n","    print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n","    print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n","    print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n","    print('\\t - Validation Specificity: {:.4f}\\n'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zivAC2aQY8hp","executionInfo":{"status":"ok","timestamp":1677356582133,"user_tz":300,"elapsed":269008,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"f6f51fe3-2691-44fa-e93c-8264d1440486"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]},{"output_type":"stream","name":"stderr","text":["Epoch:  50%|█████     | 1/2 [02:15<02:15, 135.63s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","\t - Train loss: 0.5647\n","\t - Validation Accuracy: 0.3294\n","\t - Validation Precision: 0.9692\n","\t - Validation Recall: 0.9668\n","\t - Validation Specificity: 0.9790\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch: 100%|██████████| 2/2 [04:28<00:00, 134.34s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","\t - Train loss: 0.3542\n","\t - Validation Accuracy: 0.3282\n","\t - Validation Precision: 0.9848\n","\t - Validation Recall: 0.9860\n","\t - Validation Specificity: 0.9894\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["#new_sentence = 'WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.'\n","new_sentence = 'You are an ugly girl'\n","# We need Token IDs and Attention Mask for inference on the new sentence\n","test_ids = []\n","test_attention_mask = []\n","\n","# Apply the tokenizer\n","encoding = preprocessing(new_sentence, tokenizer)\n","\n","# Extract IDs and Attention Mask\n","test_ids.append(encoding['input_ids'])\n","test_attention_mask.append(encoding['attention_mask'])\n","test_ids = torch.cat(test_ids, dim = 0)\n","test_attention_mask = torch.cat(test_attention_mask, dim = 0)\n","\n","# Forward pass, calculate logit predictions\n","with torch.no_grad():\n","  output = model(test_ids.to(device), token_type_ids = None, attention_mask = test_attention_mask.to(device))\n","\n","#prediction = 'Spam' if np.argmax(output.logits.cpu().numpy()).flatten().item() == 1 else 'Ham'\n","prediction = np.argmax(output.logits.cpu().numpy()).flatten().item()\n","\n","\n","print('Input Sentence: ', new_sentence)\n","print('Predicted Class: ', prediction)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hTgETXThZOPY","executionInfo":{"status":"ok","timestamp":1677356844016,"user_tz":300,"elapsed":312,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"6a24056d-5c0c-484e-d820-c385ab8f7296"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input Sentence:  You are an ugly girl\n","Predicted Class:  3\n"]}]},{"cell_type":"code","source":["len(test_ids[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UovfiJiRdVKo","executionInfo":{"status":"ok","timestamp":1677264773343,"user_tz":300,"elapsed":326,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"b754d38e-002a-4602-85cb-b62519500a88"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["32"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["encoding"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qo4P6b74dXNq","executionInfo":{"status":"ok","timestamp":1677264775555,"user_tz":300,"elapsed":334,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"f8e5d9d0-5a0c-4b6f-f208-9e0511364ef1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[    1, 67991,   300,   300,   463,   266,  6119,  1191,  1099,   274,\n","           286,   331,  2068,   264,  1069,   452, 28427,   962,  4597,  5505,\n","           300,   502,  1674,   660,  7993, 60489, 39908, 45500,   260, 21049,\n","          1197,     2]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1]])}"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["output.logits.cpu().numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A3pYnoAQdbCf","executionInfo":{"status":"ok","timestamp":1677264781092,"user_tz":300,"elapsed":302,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"6acfd806-5955-4cd8-8019-86b443774094"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-2.6940677,  2.7711425]], dtype=float32)"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["type(np.argmax(output.logits.cpu().numpy()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f_xye0nKgPeq","executionInfo":{"status":"ok","timestamp":1677264785052,"user_tz":300,"elapsed":304,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"38dea172-c759-47c4-ff2f-bc7bb98aa245"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.int64"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["np.argmax(output.logits.cpu().numpy()).flatten()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YFoLPmcfgloN","executionInfo":{"status":"ok","timestamp":1677264788881,"user_tz":300,"elapsed":301,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"6a55a5e3-5942-4c39-8bf9-7ac3cc14abad"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1])"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["np.argmax(output.logits.cpu().numpy()).flatten().item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m8hV-i4xg1oX","executionInfo":{"status":"ok","timestamp":1677264792423,"user_tz":300,"elapsed":300,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"bc61c066-19b0-4dfa-b2d7-e4697691613f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["type(np.argmax(output.logits.cpu().numpy()).flatten().item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d5nZyOPxg_hj","executionInfo":{"status":"ok","timestamp":1677264796311,"user_tz":300,"elapsed":326,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"813f2eb3-069d-41a0-99ac-f9d089149105"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["int"]},"metadata":{},"execution_count":34}]}]}