{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"11QTZhH6bFJtK65OVTY8P9Y85on-ZEMlL","timestamp":1677270091757},{"file_id":"17EUnGuMD8zVFOn3cvMdFjYo7C_cdWcB-","timestamp":1677106793467}],"mount_file_id":"1pCQYcjiXjSQrZUpmIErpnWO7xv2tNukl","authorship_tag":"ABX9TyNglDkYn38ms4r0+PcDuIFL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"eaba07d9fb854c9f94cdf7c77ecf726e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_16714a158c63421db55024139ddae2a5","IPY_MODEL_691866c3b4974b6ab57660dafd0ddf54","IPY_MODEL_bfc5547cf7c64d69a13670dc2f18e1f4"],"layout":"IPY_MODEL_237344a4fa2540c89fd8d062c2501166"}},"16714a158c63421db55024139ddae2a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1c65f09f556461aac82d2ac3cbe219c","placeholder":"​","style":"IPY_MODEL_68c757df1b1f46639d529d7aa3a188c4","value":"Downloading (…)okenizer_config.json: 100%"}},"691866c3b4974b6ab57660dafd0ddf54":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e714ee1344714e0bb59239113fb265c0","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_88e47f52ea57401d822a9e562a0eefe6","value":52}},"bfc5547cf7c64d69a13670dc2f18e1f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2b610dbaaac495fbf70f74568eca3a9","placeholder":"​","style":"IPY_MODEL_d5f6ca20b7024ceba8eccaf9fdbcfca9","value":" 52.0/52.0 [00:00&lt;00:00, 1.32kB/s]"}},"237344a4fa2540c89fd8d062c2501166":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1c65f09f556461aac82d2ac3cbe219c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68c757df1b1f46639d529d7aa3a188c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e714ee1344714e0bb59239113fb265c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88e47f52ea57401d822a9e562a0eefe6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c2b610dbaaac495fbf70f74568eca3a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5f6ca20b7024ceba8eccaf9fdbcfca9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca44623e691f4ca192622f7f59b70b9b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_43663bc2e8ee4bf6ac0137a64539c1f9","IPY_MODEL_93698319e8ac48e892ad87af64c1c656","IPY_MODEL_d4e6106f544a44ce9472124fca7901cf"],"layout":"IPY_MODEL_183894ef6e304bb8b0c2d9f9895bb2af"}},"43663bc2e8ee4bf6ac0137a64539c1f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_967948cd52434f36bd51ba0fc09d5b30","placeholder":"​","style":"IPY_MODEL_77f65af2097b42ec864b952f0d80748b","value":"Downloading (…)lve/main/config.json: 100%"}},"93698319e8ac48e892ad87af64c1c656":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ac811a7e8784f2cb6a20407ab1b6303","max":578,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fbcce57eb98c4d58bf32ab3f3243798b","value":578}},"d4e6106f544a44ce9472124fca7901cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_374f6ac4f7d24f89ac41d2dcca8c2cbb","placeholder":"​","style":"IPY_MODEL_209f026ddaa247cc92e08dba7e45cf68","value":" 578/578 [00:00&lt;00:00, 14.2kB/s]"}},"183894ef6e304bb8b0c2d9f9895bb2af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"967948cd52434f36bd51ba0fc09d5b30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77f65af2097b42ec864b952f0d80748b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ac811a7e8784f2cb6a20407ab1b6303":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbcce57eb98c4d58bf32ab3f3243798b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"374f6ac4f7d24f89ac41d2dcca8c2cbb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"209f026ddaa247cc92e08dba7e45cf68":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b2837b3260b431885ac8954a536928e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dc6b9b822b5848cebc1747d0485371a2","IPY_MODEL_391d39ed89ef4f0b9d62632717e23406","IPY_MODEL_b8f0f5f7dff7404f83add021fa5ecbac"],"layout":"IPY_MODEL_4023de8ea720493ca876227372a4d94c"}},"dc6b9b822b5848cebc1747d0485371a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90b9bef670084dfdbbb4a293e753b040","placeholder":"​","style":"IPY_MODEL_7ea6a5efea7d413993eee2ab8f88e7f9","value":"Downloading (…)&quot;spm.model&quot;;: 100%"}},"391d39ed89ef4f0b9d62632717e23406":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2df3d54c61e44318ab69278b13d79cd9","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b8c1b39b721f48408a1e5c30b0a09b07","value":2464616}},"b8f0f5f7dff7404f83add021fa5ecbac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4f3d3f2a44e414a858295d177fbc336","placeholder":"​","style":"IPY_MODEL_8d8ddae01e834cb0bf7c7b83dda41fb3","value":" 2.46M/2.46M [00:00&lt;00:00, 22.1MB/s]"}},"4023de8ea720493ca876227372a4d94c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90b9bef670084dfdbbb4a293e753b040":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ea6a5efea7d413993eee2ab8f88e7f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2df3d54c61e44318ab69278b13d79cd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8c1b39b721f48408a1e5c30b0a09b07":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c4f3d3f2a44e414a858295d177fbc336":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d8ddae01e834cb0bf7c7b83dda41fb3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# This is the Fine-Tuning for Text Classification simple example\n","- https://towardsdatascience.com/fine-tuning-bert-for-text-classification-54e7df642894"],"metadata":{"id":"eLD0nCN1Ufok"}},{"cell_type":"code","source":["# put drive connection code if needed\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"rTMPrUQbW_Rt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git config --global user.email \"bgoldfe2@gmu.edu\"\n","!git config --global user.name \"Bruce Goldfeder\"\n","!cp -R ssh ~/.ssh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rr0z2WrsQRyY","executionInfo":{"status":"ok","timestamp":1677272905036,"user_tz":300,"elapsed":1300,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"a30bc307-e7ee-4b01-d235-b39abd5e458d"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["cp: cannot stat 'ssh': No such file or directory\n"]}]},{"cell_type":"code","source":["# Code to install the nightly version if needed for debugging\n","\n","#!nvcc --version\n","#!pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu117"],"metadata":{"id":"sV4rdGMLpL3n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers\n","!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FOjkyiXPUF3b","executionInfo":{"status":"ok","timestamp":1677270333786,"user_tz":300,"elapsed":16924,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"028e4e19-e1a9-454e-81bc-68496e0a0ffa"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.26.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"5lz0BNh8T8Rm","executionInfo":{"status":"ok","timestamp":1677270366237,"user_tz":300,"elapsed":6904,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}}},"outputs":[],"source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","#from transformers import BertTokenizer, BertForSequenceClassification\n","from transformers import AutoModelForSequenceClassification,AutoTokenizer\n","from sklearn.model_selection import train_test_split\n","\n","import pandas as pd\n","import numpy as np\n","\n","from tabulate import tabulate\n","from tqdm import trange\n","import random\n","import math\n","\n","import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""]},{"cell_type":"code","source":["!pwd\n","%cd drive/MyDrive/Github/dissertation-ground-up-version/Dataset/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HXaLxOjOT9fn","executionInfo":{"status":"ok","timestamp":1677270466094,"user_tz":300,"elapsed":264,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"8d54539a-ca34-4106-954f-fbfc5b5173d9"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/drive/MyDrive/Github/dissertation-ground-up-version/Dataset\n"]}]},{"cell_type":"code","source":["%cd SixClass/\n","!head -10 train.csv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hpCzALb8UeN6","executionInfo":{"status":"ok","timestamp":1677270536950,"user_tz":300,"elapsed":461,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"91376d2c-2dca-453e-9278-05a51c7c0320"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Github/dissertation-ground-up-version/Dataset/SixClass\n",",text,label,target\n","38746,#trumprussia sean spicer is a blithering idiot who will repeat anything trump tells him.,Others,4\n","47265,\"If you call yourself a Christian yet you support this bill and the man pushing for it, you should be ashamed of yourself! Jesus Christ himself was radical during his time. And if he were here present today, he will be crucified again under this proposed law. #JUNKTERRORBILLNOW\",Religion,5\n","36632,Small red lights in dark rooms.,Others,4\n","29064,\"If u find yourself pouting that no male reporters were recognized at ONE press conference, u just tasted the bitterness of millennia 4 women\",Notcb,3\n","33884,Messi carried these retards to three consecutive finals. Unbelievablâ¦,Others,4\n","26525,#MKR France Vs Ireland Vs Paleo Pete...LETS RUMBLE!,Notcb,3\n","41797,\"Today's front page of the New York Times. A full on assault on YouTubers. Story claims videos are \"\"radicalizing people\"\" on the right. Their evidence...the guy featured in the story started dating a Christian woman and supported traditional gender roles. oh no!!!!!!!!\",Religion,5\n","33241,too bad I'm a size 11 men and got basketball torn up ass feet ð¤·ð½ââï¸ https://t.co/xWDblad389,Others,4\n","11082,@_sarahjessiee @Khalil_Perry fuck that dumb ass nigger @TreySongz,Ethnicity,1\n"]}]},{"cell_type":"code","source":["df = pd.read_csv(\"train.csv\")\n","\n","# First 5 rows\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"Rtu_2nO0VLzg","executionInfo":{"status":"ok","timestamp":1677271778202,"user_tz":300,"elapsed":256,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"4bc8a0bd-1752-46da-a996-a6b5360aa3de"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0                                               text     label  \\\n","0       38746  #trumprussia sean spicer is a blithering idiot...    Others   \n","1       47265  If you call yourself a Christian yet you suppo...  Religion   \n","2       36632                    Small red lights in dark rooms.    Others   \n","3       29064  If u find yourself pouting that no male report...     Notcb   \n","4       33884  Messi carried these retards to three consecuti...    Others   \n","\n","   target  \n","0       4  \n","1       5  \n","2       4  \n","3       3  \n","4       4  "],"text/html":["\n","  <div id=\"df-d5667f3f-a1c1-4123-830c-f1d8d1d44179\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>38746</td>\n","      <td>#trumprussia sean spicer is a blithering idiot...</td>\n","      <td>Others</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>47265</td>\n","      <td>If you call yourself a Christian yet you suppo...</td>\n","      <td>Religion</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36632</td>\n","      <td>Small red lights in dark rooms.</td>\n","      <td>Others</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>29064</td>\n","      <td>If u find yourself pouting that no male report...</td>\n","      <td>Notcb</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>33884</td>\n","      <td>Messi carried these retards to three consecuti...</td>\n","      <td>Others</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5667f3f-a1c1-4123-830c-f1d8d1d44179')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d5667f3f-a1c1-4123-830c-f1d8d1d44179 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d5667f3f-a1c1-4123-830c-f1d8d1d44179');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["df.drop(df.columns[[0, 2]], axis=1, inplace=True)\n","df.rename(columns = {'target':'label'}, inplace = True)\n","display(df.head())\n","\n","text = df.text.values\n","labels = df.label.values"],"metadata":{"id":"Iai7SUzGVQ4H","executionInfo":{"status":"ok","timestamp":1677271781486,"user_tz":300,"elapsed":114,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"530ddb07-47e9-472e-b4c0-cfb9bc13f1ee"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":["                                                text  label\n","0  #trumprussia sean spicer is a blithering idiot...      4\n","1  If you call yourself a Christian yet you suppo...      5\n","2                    Small red lights in dark rooms.      4\n","3  If u find yourself pouting that no male report...      3\n","4  Messi carried these retards to three consecuti...      4"],"text/html":["\n","  <div id=\"df-64b94f0f-96da-4906-b9b9-77a9c4cc6d8e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>#trumprussia sean spicer is a blithering idiot...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>If you call yourself a Christian yet you suppo...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Small red lights in dark rooms.</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>If u find yourself pouting that no male report...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Messi carried these retards to three consecuti...</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64b94f0f-96da-4906-b9b9-77a9c4cc6d8e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-64b94f0f-96da-4906-b9b9-77a9c4cc6d8e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-64b94f0f-96da-4906-b9b9-77a9c4cc6d8e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["df.groupby(['label']).size().plot.bar()\n","\n","# Need to implement custom Dataset as in https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"id":"AbN6Nlc0PN-y","executionInfo":{"status":"ok","timestamp":1677272711114,"user_tz":300,"elapsed":289,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"6925b0cc-3f7e-44ac-cfd9-373dab361446"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<AxesSubplot:xlabel='label'>"]},"metadata":{},"execution_count":23},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["model_nm = 'microsoft/deberta-v3-small'\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_nm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202,"referenced_widgets":["eaba07d9fb854c9f94cdf7c77ecf726e","16714a158c63421db55024139ddae2a5","691866c3b4974b6ab57660dafd0ddf54","bfc5547cf7c64d69a13670dc2f18e1f4","237344a4fa2540c89fd8d062c2501166","b1c65f09f556461aac82d2ac3cbe219c","68c757df1b1f46639d529d7aa3a188c4","e714ee1344714e0bb59239113fb265c0","88e47f52ea57401d822a9e562a0eefe6","c2b610dbaaac495fbf70f74568eca3a9","d5f6ca20b7024ceba8eccaf9fdbcfca9","ca44623e691f4ca192622f7f59b70b9b","43663bc2e8ee4bf6ac0137a64539c1f9","93698319e8ac48e892ad87af64c1c656","d4e6106f544a44ce9472124fca7901cf","183894ef6e304bb8b0c2d9f9895bb2af","967948cd52434f36bd51ba0fc09d5b30","77f65af2097b42ec864b952f0d80748b","6ac811a7e8784f2cb6a20407ab1b6303","fbcce57eb98c4d58bf32ab3f3243798b","374f6ac4f7d24f89ac41d2dcca8c2cbb","209f026ddaa247cc92e08dba7e45cf68","1b2837b3260b431885ac8954a536928e","dc6b9b822b5848cebc1747d0485371a2","391d39ed89ef4f0b9d62632717e23406","b8f0f5f7dff7404f83add021fa5ecbac","4023de8ea720493ca876227372a4d94c","90b9bef670084dfdbbb4a293e753b040","7ea6a5efea7d413993eee2ab8f88e7f9","2df3d54c61e44318ab69278b13d79cd9","b8c1b39b721f48408a1e5c30b0a09b07","c4f3d3f2a44e414a858295d177fbc336","8d8ddae01e834cb0bf7c7b83dda41fb3"]},"id":"TLGat00iVUzq","executionInfo":{"status":"ok","timestamp":1677271830039,"user_tz":300,"elapsed":4538,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"90da428a-599e-439a-b40c-a95615bd9078"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eaba07d9fb854c9f94cdf7c77ecf726e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca44623e691f4ca192622f7f59b70b9b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)\"spm.model\";:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b2837b3260b431885ac8954a536928e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","/usr/local/lib/python3.8/dist-packages/transformers/convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["print(type(tokenizer))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VH7DtwaqiiV9","executionInfo":{"status":"ok","timestamp":1677271832811,"user_tz":300,"elapsed":111,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"d8592137-4b66-4785-db4d-84ffcfe8d6e3"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'transformers.models.deberta_v2.tokenization_deberta_v2_fast.DebertaV2TokenizerFast'>\n"]}]},{"cell_type":"code","source":["def print_rand_sentence():\n","  '''Displays the tokens and respective IDs of a random text sample'''\n","  index = random.randint(0, len(text)-1)\n","  table = np.array([tokenizer.tokenize(text[index]), \n","                    tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text[index]))]).T\n","  print(tabulate(table,\n","                 headers = ['Tokens', 'Token IDs'],\n","                 tablefmt = 'fancy_grid'))\n","\n","print_rand_sentence()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zzqWr_EpVa88","executionInfo":{"status":"ok","timestamp":1677271848607,"user_tz":300,"elapsed":98,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"2a48f6c7-a8db-416f-9975-2a5addd967e5"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["╒══════════╤═════════════╕\n","│ Tokens   │   Token IDs │\n","╞══════════╪═════════════╡\n","│ ▁some    │         347 │\n","├──────────┼─────────────┤\n","│ ▁kid     │        3221 │\n","├──────────┼─────────────┤\n","│ ▁on      │         277 │\n","├──────────┼─────────────┤\n","│ ▁my      │         312 │\n","├──────────┼─────────────┤\n","│ ▁bus     │        2444 │\n","├──────────┼─────────────┤\n","│ ▁made    │         412 │\n","├──────────┼─────────────┤\n","│ ▁rape    │       18712 │\n","├──────────┼─────────────┤\n","│ ▁jokes   │       10692 │\n","├──────────┼─────────────┤\n","│ ▁and     │         263 │\n","├──────────┼─────────────┤\n","│ ▁gay     │        4733 │\n","├──────────┼─────────────┤\n","│ ▁jokes   │       10692 │\n","├──────────┼─────────────┤\n","│ ▁and     │         263 │\n","├──────────┼─────────────┤\n","│ ▁made    │         412 │\n","├──────────┼─────────────┤\n","│ ▁fun     │         785 │\n","├──────────┼─────────────┤\n","│ ▁of      │         265 │\n","├──────────┼─────────────┤\n","│ ▁his     │         315 │\n","├──────────┼─────────────┤\n","│ ▁\"       │         307 │\n","├──────────┼─────────────┤\n","│ friend   │       26399 │\n","├──────────┼─────────────┤\n","│ \"        │         309 │\n","├──────────┼─────────────┤\n","│ ▁for     │         270 │\n","├──────────┼─────────────┤\n","│ ▁no      │         363 │\n","├──────────┼─────────────┤\n","│ ▁reason  │         919 │\n","├──────────┼─────────────┤\n","│ .        │         260 │\n","├──────────┼─────────────┤\n","│ ▁what    │         339 │\n","├──────────┼─────────────┤\n","│ ▁a       │         266 │\n","├──────────┼─────────────┤\n","│ ▁bag     │        2208 │\n","├──────────┼─────────────┤\n","│ ▁of      │         265 │\n","├──────────┼─────────────┤\n","│ ▁shit    │       17197 │\n","╘══════════╧═════════════╛\n"]}]},{"cell_type":"code","source":["token_id = []\n","attention_masks = []\n","\n","def preprocessing(input_text, tokenizer):\n","  '''\n","  Returns <class transformers.tokenization_utils_base.BatchEncoding> with the following fields:\n","    - input_ids: list of token ids\n","    - token_type_ids: list of token type ids\n","    - attention_mask: list of indices (0,1) specifying which tokens should considered by the model (return_attention_mask = True).\n","  '''\n","  return tokenizer.encode_plus(\n","                        input_text,\n","                        add_special_tokens = True,\n","                        max_length = 128,\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,\n","                        return_tensors = 'pt'\n","                   )\n","\n","\n","for sample in text:\n","  encoding_dict = preprocessing(sample, tokenizer)\n","  token_id.append(encoding_dict['input_ids']) \n","  attention_masks.append(encoding_dict['attention_mask'])\n","\n","\n","token_id = torch.cat(token_id, dim = 0)\n","attention_masks = torch.cat(attention_masks, dim = 0)\n","labels = torch.tensor(labels)"],"metadata":{"id":"1hs9CF6TVkeX","executionInfo":{"status":"ok","timestamp":1677271908732,"user_tz":300,"elapsed":14544,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["token_id[6]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y-CaLReyWYGz","executionInfo":{"status":"ok","timestamp":1677271915518,"user_tz":300,"elapsed":119,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"5cea995a-2031-4da3-ae91-e9034d208fb0"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([    1,  1715,   280,   268,   831,   664,   265,   262,   485,   920,\n","         2921,   260,   336,   540,   277,  5292,   277, 88953,   260,  5372,\n","         2071,  2340,   281,   307, 45008,  5415,   355,   309,   277,   262,\n","          423,   260,  2135,  1519,   260,   260,   260,   724,  1863,  3103,\n","          267,   262,   697,   696,  2591,   266,  2132,  1220,   263,  2560,\n","         1471,  3790,  3930,   260,  6359,   363,   300,   300,   300,   300,\n","          300,   300,   300,   300,     2,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["def print_rand_sentence_encoding():\n","  '''Displays tokens, token IDs and attention mask of a random text sample'''\n","  index = random.randint(0, len(text) - 1)\n","  tokens = tokenizer.tokenize(tokenizer.decode(token_id[index]))\n","  token_ids = [i.numpy() for i in token_id[index]]\n","  attention = [i.numpy() for i in attention_masks[index]]\n","\n","  table = np.array([tokens, token_ids, attention]).T\n","  print(tabulate(table, \n","                 headers = ['Tokens', 'Token IDs', 'Attention Mask'],\n","                 tablefmt = 'fancy_grid'))\n","\n","print_rand_sentence_encoding()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8HXLgfPCWdfJ","executionInfo":{"status":"ok","timestamp":1677271929019,"user_tz":300,"elapsed":106,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"50b4b9d5-f392-4167-96e6-05e5a28a0646"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["╒═════════════╤═════════════╤══════════════════╕\n","│ Tokens      │   Token IDs │   Attention Mask │\n","╞═════════════╪═════════════╪══════════════════╡\n","│ [CLS]       │           1 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁Let        │        1448 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁me         │         351 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁tell       │         848 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁u          │        3636 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ,           │         261 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁Trump      │        1002 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁say        │         504 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁loud       │        5320 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁&          │         429 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ amp         │       10832 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ;           │         346 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁clear      │         913 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ .           │         260 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁Radical    │       27235 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁Islamic    │        5016 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁terrorism  │        8216 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁is         │         269 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁2          │         392 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁b          │        2165 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁uprooted   │       63926 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ .           │         260 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁V          │        1407 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁can        │         295 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ '           │         280 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ t           │         297 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁let        │         678 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁anyone     │        1012 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁spread     │        2443 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁d          │        1931 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁virus      │        5336 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁or         │         289 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁do         │         333 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁Je         │       16552 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ had         │       13786 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁on         │         277 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁Indian     │        2054 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁Land       │        4107 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁regardless │        3948 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁to         │         264 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁d          │        1931 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁religion   │        3792 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ .           │         260 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ▁#          │         953 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ abol        │       42585 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ ish         │        4615 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ muslim      │      111777 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ personal    │       18399 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ law         │        5697 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ board       │        6511 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [SEP]       │           2 │                1 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","├─────────────┼─────────────┼──────────────────┤\n","│ [PAD]       │           0 │                0 │\n","╘═════════════╧═════════════╧══════════════════╛\n"]}]},{"cell_type":"code","source":["val_ratio = 0.2\n","# Recommended batch size: 16, 32. See: https://arxiv.org/pdf/1810.04805.pdf\n","batch_size = 16\n","\n","# Indices of the train and validation splits stratified by labels\n","train_idx, val_idx = train_test_split(\n","    np.arange(len(labels)),\n","    test_size = val_ratio,\n","    shuffle = True,\n","    stratify = labels)\n","\n","# Train and validation sets\n","train_set = TensorDataset(token_id[train_idx], \n","                          attention_masks[train_idx], \n","                          labels[train_idx])\n","\n","val_set = TensorDataset(token_id[val_idx], \n","                        attention_masks[val_idx], \n","                        labels[val_idx])\n","\n","# Prepare DataLoader\n","train_dataloader = DataLoader(\n","            train_set,\n","            sampler = RandomSampler(train_set),\n","            batch_size = batch_size\n","        )\n","\n","validation_dataloader = DataLoader(\n","            val_set,\n","            sampler = SequentialSampler(val_set),\n","            batch_size = batch_size\n","        )"],"metadata":{"id":"-UY6ZhNQWn45","executionInfo":{"status":"ok","timestamp":1677271946146,"user_tz":300,"elapsed":115,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def b_tp(preds, labels):\n","  '''Returns True Positives (TP): count of correct predictions of actual class 1'''\n","  return sum([preds == labels and preds == 1 for preds, labels in zip(preds, labels)])\n","\n","def b_fp(preds, labels):\n","  '''Returns False Positives (FP): count of wrong predictions of actual class 1'''\n","  return sum([preds != labels and preds == 1 for preds, labels in zip(preds, labels)])\n","\n","def b_tn(preds, labels):\n","  '''Returns True Negatives (TN): count of correct predictions of actual class 0'''\n","  return sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)])\n","\n","def b_fn(preds, labels):\n","  '''Returns False Negatives (FN): count of wrong predictions of actual class 0'''\n","  return sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n","\n","def b_metrics(preds, labels):\n","  '''\n","  Returns the following metrics:\n","    - accuracy    = (TP + TN) / N\n","    - precision   = TP / (TP + FP)\n","    - recall      = TP / (TP + FN)\n","    - specificity = TN / (TN + FP)\n","  '''\n","  preds = np.argmax(preds, axis = 1).flatten()\n","  labels = labels.flatten()\n","  tp = b_tp(preds, labels)\n","  tn = b_tn(preds, labels)\n","  fp = b_fp(preds, labels)\n","  fn = b_fn(preds, labels)\n","  b_accuracy = (tp + tn) / len(labels)\n","  b_precision = tp / (tp + fp) if (tp + fp) > 0 else 'nan'\n","  b_recall = tp / (tp + fn) if (tp + fn) > 0 else 'nan'\n","  b_specificity = tn / (tn + fp) if (tn + fp) > 0 else 'nan'\n","  return b_accuracy, b_precision, b_recall, b_specificity"],"metadata":{"id":"t9RO9ncOYH_B","executionInfo":{"status":"ok","timestamp":1677272025076,"user_tz":300,"elapsed":103,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Load the SequenceClassification model\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    model_nm,\n","    num_labels = 6,\n","    output_attentions = False,\n","    output_hidden_states = False,\n",")\n","\n","# Recommended learning rates (Adam): 5e-5, 3e-5, 2e-5. See: https://arxiv.org/pdf/1810.04805.pdf\n","optimizer = torch.optim.AdamW(model.parameters(), \n","                              lr = 5e-5,\n","                              eps = 1e-08\n","                              )\n","\n","# Run on GPU\n","model.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H2QNBChoYScs","executionInfo":{"status":"ok","timestamp":1677272115565,"user_tz":300,"elapsed":2850,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"5da9caa9-66bc-4832-da41-5be7c81e6f70"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-small were not used when initializing DebertaV2ForSequenceClassification: ['lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["DebertaV2ForSequenceClassification(\n","  (deberta): DebertaV2Model(\n","    (embeddings): DebertaV2Embeddings(\n","      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n","      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","      (dropout): StableDropout()\n","    )\n","    (encoder): DebertaV2Encoder(\n","      (layer): ModuleList(\n","        (0): DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (1): DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (2): DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (3): DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (4): DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (5): DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","      )\n","      (rel_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","    )\n","  )\n","  (pooler): ContextPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): StableDropout()\n","  )\n","  (classifier): Linear(in_features=768, out_features=6, bias=True)\n","  (dropout): StableDropout()\n",")"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","\n","# Recommended number of epochs: 2, 3, 4. See: https://arxiv.org/pdf/1810.04805.pdf\n","epochs = 2\n","\n","for _ in trange(epochs, desc = 'Epoch'):\n","    \n","    # ========== Training ==========\n","    \n","    # Set model to training mode\n","    model.train()\n","    \n","    # Tracking variables\n","    tr_loss = 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","\n","    for step, batch in enumerate(train_dataloader):\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","        optimizer.zero_grad()\n","        # Forward pass\n","        train_output = model(b_input_ids, \n","                             token_type_ids = None, \n","                             attention_mask = b_input_mask, \n","                             labels = b_labels)\n","        # Backward pass\n","        train_output.loss.backward()\n","        optimizer.step()\n","        # Update tracking variables\n","        tr_loss += train_output.loss.item()\n","        nb_tr_examples += b_input_ids.size(0)\n","        nb_tr_steps += 1\n","\n","    # ========== Validation ==========\n","\n","    # Set model to evaluation mode\n","    model.eval()\n","\n","    # Tracking variables \n","    val_accuracy = []\n","    val_precision = []\n","    val_recall = []\n","    val_specificity = []\n","\n","    for batch in validation_dataloader:\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","        with torch.no_grad():\n","          # Forward pass\n","          eval_output = model(b_input_ids, \n","                              token_type_ids = None, \n","                              attention_mask = b_input_mask)\n","        logits = eval_output.logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        # Calculate validation metrics\n","        b_accuracy, b_precision, b_recall, b_specificity = b_metrics(logits, label_ids)\n","        val_accuracy.append(b_accuracy)\n","        # Update precision only when (tp + fp) !=0; ignore nan\n","        if b_precision != 'nan': val_precision.append(b_precision)\n","        # Update recall only when (tp + fn) !=0; ignore nan\n","        if b_recall != 'nan': val_recall.append(b_recall)\n","        # Update specificity only when (tn + fp) !=0; ignore nan\n","        if b_specificity != 'nan': val_specificity.append(b_specificity)\n","\n","    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n","    print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n","    print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n","    print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n","    print('\\t - Validation Specificity: {:.4f}\\n'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":536},"id":"zivAC2aQY8hp","executionInfo":{"status":"error","timestamp":1677272692706,"user_tz":300,"elapsed":543087,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"55a4b8bc-ae41-4546-fb89-46a9ed07a06b"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]},{"output_type":"stream","name":"stderr","text":["Epoch:  50%|█████     | 1/2 [08:11<08:11, 491.95s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","\t - Train loss: 0.5575\n","\t - Validation Accuracy: 0.3305\n","\t - Validation Precision: 0.9717\n","\t - Validation Recall: 0.9634\n","\t - Validation Specificity: 0.9761\n","\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  50%|█████     | 1/2 [09:02<09:02, 542.97s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-991627b3d998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m                              labels = b_labels)\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mtrain_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Update tracking variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["new_sentence = 'WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.'\n","\n","# We need Token IDs and Attention Mask for inference on the new sentence\n","test_ids = []\n","test_attention_mask = []\n","\n","# Apply the tokenizer\n","encoding = preprocessing(new_sentence, tokenizer)\n","\n","# Extract IDs and Attention Mask\n","test_ids.append(encoding['input_ids'])\n","test_attention_mask.append(encoding['attention_mask'])\n","test_ids = torch.cat(test_ids, dim = 0)\n","test_attention_mask = torch.cat(test_attention_mask, dim = 0)\n","\n","# Forward pass, calculate logit predictions\n","with torch.no_grad():\n","  output = model(test_ids.to(device), token_type_ids = None, attention_mask = test_attention_mask.to(device))\n","\n","prediction = 'Spam' if np.argmax(output.logits.cpu().numpy()).flatten().item() == 1 else 'Ham'\n","\n","print('Input Sentence: ', new_sentence)\n","print('Predicted Class: ', prediction)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hTgETXThZOPY","executionInfo":{"status":"ok","timestamp":1677270056160,"user_tz":300,"elapsed":574,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"02eec13e-7ecb-422c-f1a5-004c93ab5843"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input Sentence:  WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\n","Predicted Class:  Spam\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["len(test_ids[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UovfiJiRdVKo","executionInfo":{"status":"ok","timestamp":1677264773343,"user_tz":300,"elapsed":326,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"b754d38e-002a-4602-85cb-b62519500a88"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["32"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["encoding"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qo4P6b74dXNq","executionInfo":{"status":"ok","timestamp":1677264775555,"user_tz":300,"elapsed":334,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"f8e5d9d0-5a0c-4b6f-f208-9e0511364ef1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[    1, 67991,   300,   300,   463,   266,  6119,  1191,  1099,   274,\n","           286,   331,  2068,   264,  1069,   452, 28427,   962,  4597,  5505,\n","           300,   502,  1674,   660,  7993, 60489, 39908, 45500,   260, 21049,\n","          1197,     2]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1]])}"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["output.logits.cpu().numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A3pYnoAQdbCf","executionInfo":{"status":"ok","timestamp":1677264781092,"user_tz":300,"elapsed":302,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"6acfd806-5955-4cd8-8019-86b443774094"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-2.6940677,  2.7711425]], dtype=float32)"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["type(np.argmax(output.logits.cpu().numpy()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f_xye0nKgPeq","executionInfo":{"status":"ok","timestamp":1677264785052,"user_tz":300,"elapsed":304,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"38dea172-c759-47c4-ff2f-bc7bb98aa245"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.int64"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["np.argmax(output.logits.cpu().numpy()).flatten()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YFoLPmcfgloN","executionInfo":{"status":"ok","timestamp":1677264788881,"user_tz":300,"elapsed":301,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"6a55a5e3-5942-4c39-8bf9-7ac3cc14abad"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1])"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["np.argmax(output.logits.cpu().numpy()).flatten().item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m8hV-i4xg1oX","executionInfo":{"status":"ok","timestamp":1677264792423,"user_tz":300,"elapsed":300,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"bc61c066-19b0-4dfa-b2d7-e4697691613f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["type(np.argmax(output.logits.cpu().numpy()).flatten().item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d5nZyOPxg_hj","executionInfo":{"status":"ok","timestamp":1677264796311,"user_tz":300,"elapsed":326,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"813f2eb3-069d-41a0-99ac-f9d089149105"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["int"]},"metadata":{},"execution_count":34}]}]}